# -*- coding: utf-8 -*-
"""EDA_TITANIC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XVxBsf9FScpNcZ5QY97GZhs9thnnUjl
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

file_path='/content/drive/My Drive/Titanic/train.csv'

df=pd.read_csv(file_path)

df.head()

"""Why EDA used ?


*   Model building
*   Analysis and reporting
*   validate assumption
*   handling missing value
*   feature engineering
*   detecting outliers

# Column type
* Numerical- Age,Fare,PassengerID
* Categorical-Survived,Pclass,Sex,SibSp,Parch,Embarked
* Mix type-Name,Ticket,Cabin

**Univariate analysis** involves examining the distribution and characteristics of a single variable in a dataset. It helps to understand the central tendency, dispersion, and shape of the variable's distribution.
* Summary Statistics: **bold text** Calculate descriptive statistics such as mean, median, mode, range, standard deviation, and variance. This provides an overview of the central tendency and dispersion of the variable.

* **Histogram:** Plot a histogram to visualize the frequency distribution of the variable. It helps to understand the shape of the distribution and detect any outliers.

* **Box Plot:** Create a box plot to visualize the median, quartiles, and potential outliers in the data. This helps to identify the spread and skewness of the distribution.


* **Bar Plot (for Numerical variables):** If the variable is Numerical, you can create a bar plot to visualize the frequency of each category. This helps to understand the distribution of Numerical variables.

* **Percentiles:** Calculate percentiles to identify specific data points such as the 25th, 50th (median), and 75th percentiles. This provides insights into the spread of the data and helps identify potential outliers.

# Analysis on Age Column
"""

df['Age']

df['Age'].describe()

df['Age'].plot(kind='hist',bins=20)

df['Age'].plot(kind='kde')

df['Age'].skew()

df['Age'].max()

df['Age'].min()

df['Age'].plot(kind='box')

df[df['Age']>65]

"""Find the No of Outlier"""

Q1 = df['Age'].quantile(0.25)
Q3 = df['Age'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['Age'] < lower_bound) | (df['Age'] > upper_bound)]

num_outliers = outliers.shape[0]

print("Number of outliers:", num_outliers)
print(lower_bound)
print(upper_bound)

df['Age'].isnull().sum()

df['Age'].isnull().sum()/len(df['Age'])

"""# Conclusion on Age
* Age data with Skew value .3840 value then it is almost normally distributed
*  177 value are missing in Age in percentage 20%
* there is some outlier  which Age is greater then 64.8125

# Analysis on Fare Column
"""

df['Fare'].describe()

df['Fare'].info()

df['Fare'].plot(kind='hist',bins=20)

df['Fare'].skew()

df['Fare'].plot(kind='kde')

df['Fare'].plot(kind='box')

df[df['Fare']>90]

"""# Code for Find no outlier"""

Q1 = df['Fare'].quantile(0.25)
Q3 = df['Fare'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['Fare'] < lower_bound) | (df['Fare'] > upper_bound)]

num_outliers = outliers.shape[0]

print("Number of outliers:", num_outliers)
print(upper_bound)
print(lower_bound)

Q1=df['Age'].quantile(0.25)
Q2=df['Age'].quantile(0.75)
IQR=Q2-Q1
Lower_bound=Q1-1.5*IQR
Upper_bound=Q2+1.5*IQR
Outliers=df[(df['Age']<Lower_bound) | (df['Age']>Upper_bound)]
no_of_Outliers=Outliers.shape[0]
print(no_of_Outliers)

df['Fare'].isnull().sum()

"""# Conclusion on Fare
* Fare data with Skew value 4.787316519674893 value then it is not  normally distributed because it mean value  32.204208.normal curve is not symmetric about means
* 0 value are missing in Fare
* there is some outlier  which Fare is greater Uppper_bound **65.8125**

# Univarient Analysis on Categorical column
"""

df['Survived'].value_counts()

"""* 0-dead
* 1-Alive
"""

df['Survived'].value_counts().plot(kind='bar')

df['Survived'].value_counts().plot(kind='pie',autopct='%0.1f%%')

df['Survived'].isnull().sum()

df['Pclass'].value_counts()

df['Pclass'].value_counts().plot(kind='bar')

df['Pclass'].value_counts().plot(kind='pie',autopct='%0.01f%%')

df['Sex'].value_counts()

df['Sex'].value_counts().plot(kind='bar')

df['Sex'].value_counts().plot(kind='pie',autopct='%0.1f%%')

df['Sex'].isnull().sum()

df['SibSp'].value_counts()

df['SibSp'].value_counts().plot(kind='bar')

df['SibSp'].value_counts().plot(kind='pie',autopct='%0.1f%%')

df['Parch'].value_counts()

df['Parch'].value_counts().plot(kind='bar')

df['Parch'].value_counts().plot(kind='pie',autopct='%.1f%%')

df['Embarked'].value_counts()

df['Embarked'].value_counts().plot(kind='bar')

df['Embarked'].value_counts().plot(kind='pie',autopct='%.01f%%')

"""# **Bivariate Analysis**

**Bivariate analysis** involves exploring the relationship between two variables in a dataset. It helps to understand how the variables are related to each other and whether there exists any correlation or pattern between them.
# Type of Bivariate analysis
* **Categorical-Categorical**
When analyzing the relationship between two categorical variables, several types of plots can effectively visualize the data:


1.   Stacked Bar Plot
1.   Clustered Bar Plot:
1.   Heatmap
2.   Mosaic Plot
5.   Chi-Square Test
6.   Joint Plot (from Seaborn)



* **Categorical-Numerical**When exploring the relationship between a numerical variable and a categorical variable,several types of plots can effectively visualize the data:


1.   Box Plot
2.   Violin Plo
3.   Bar Plot
4.   Point Plot
5.   Strip Plo
6.   Swarm Plot


* **Numerical-Numerical**
When analyzing the relationship between two numerical variables, you can use several types of plots to visualize their relationship. Here are some common types of plots for numerical-numerical (also known as bivariate numerical) data:


1.   Scatter Plot
2.   Line Plot:
3.   Hexbin Plot
4.   Contour Plot
5.   Heatmap
6.   Pairplot
"""

df.shape

"""# **Now i am going to  find relation between categorical-Categorical**

# **Cross-tabulations or contingency**

# Servived & Pclass
"""

pd.crosstab(df['Survived'],df['Pclass'])

pd.crosstab(df['Survived'],df['Pclass'],normalize='columns')

pd.crosstab(df['Survived'],df['Pclass'],normalize='columns')*100

sns.heatmap(pd.crosstab(df['Survived'],df['Pclass'],normalize='columns')*100)

"""# **Conclusion**
* In pclass 3 is more people dead so this not safe for people
*  In pclass 1 less people dead so this safe for people

# Servived and Sex
"""

pd.crosstab(df['Survived'],df['Sex'],normalize='columns')

pd.crosstab(df['Survived'],df['Sex'],normalize='columns')*100

sns.heatmap(pd.crosstab(df['Survived'],df['Sex'],normalize='columns')*100)

"""# Conclusion
* ladies first mean less female dead during the tatanic excident more men dead
"""

pd.crosstab(df['Survived'],df['Embarked'],normalize='columns')

"""# what is reason less dead person in c? May be the reason they are the female or Pclass1"""

pd.crosstab(df['Sex'],df['Embarked'],normalize='columns')*100

"""# Female is not reason for more people Alive in C,may be some other reason"""

pd.crosstab(df['Pclass'],df['Embarked'],normalize='columns')*100

"""# reason is they take Pclass 1 so they are reach people

## Cetgorical-Numerical

# * Age vs Servived
"""

df[df['Survived']==1]['Age'].plot(kind='kde',label='Survived')
df[df['Survived']==0]['Age'].plot(kind='kde',label='Not Survived')
plt.legend()
plt.show()

"""* from age 0-15 year alive rate of children better then death rate but
* after the 15 death rate is more then the alive
* after 39 year people alive rate is good as compared to death rate
* after 60 year old people death rate is more then alive rate

# Mean Age in all Pclass
"""

df[df['Pclass']==1]['Age'].mean()

df[df['Pclass']==2]['Age'].mean()

df[df['Pclass']==3]['Age'].mean()

"""# Feature Engineering"""

df['SibSp'].value_counts()

df[df['SibSp']==8]

"""# in above 8 SibSp and 2 Parch and including self total no=11 but on abive information total 7 mean some data in test data set"""

69.55/11

df[df['Ticket']=='CA. 2343']

"""**Still 7 people after by searching by Ticket name**"""

file_path1='/content/drive/My Drive/Titanic/test.csv'

df1=pd.read_csv(file_path1)
df1

df2=pd.concat([df,df1])
df2

df2[df2['Ticket']=='CA. 2343']

"""**now on above total no of 11 people**"""

df2['Ticket'].value_counts()

df2[df2['Ticket']=='CA 2144']

df2['Indu_fair']=df2['Fare']/(df2['SibSp']+df2['Parch']+1)
df2

df2.shape

df2['Fare'].plot(kind='box')

df2['Indu_fair'].describe()

df2['family_size']=df2['SibSp']+df2['Parch']+1
df2

"""**Family type**
* 1-(alone)
* 2-4(small)
* (>5(large))
"""

def transform_family_size(num):
    if num == 1:
        return 'alone'
    elif 1 < num < 5:  # Corrected condition
        return "small"
    else:
        return "large"

df2['family_size'].apply(transform_family_size)

df2['family_type']=df2['family_size'].apply(transform_family_size)
df2

pd.crosstab(df2['Survived'],df2['family_type'],normalize='columns')

pd.crosstab(df2['Survived'],df2['family_type'],normalize='columns')*100

"""conclude that small family has high chance Alive but for alone and large family two **dangerous**"""

df2['Name'].str.split(',')

df2['Name'].str.split(',').str.get(0)

df2['Surname']=df2['Name'].str.split(',').str.get(0)

df2

df2['Name'].str.split(',').str.get(1).str.strip().str.split(' ')

df2['Name'].str.split(',').str.get(1).str.strip().str.split(' ')

df2['Name'].str.split(',').str.get(1).str.strip().str.split(' ').str.get(0)

df2['title']=df2['Name'].str.split(',').str.get(1).str.strip().str.split(' ').str.get(0)
df2['title']

df2

df2['title'].value_counts()

titles_to_replace = ['Rev.', 'Dr.', 'Col.', 'Major.','Capt.', 'the', 'Jonkheer.']

for title in titles_to_replace:
    df2['title'] = df2['title'].str.replace(title, 'other')

df2['title'].value_counts()

"""Above replace to other is work properly"""

temp_df=df2[df2['title'].isin(['Mr.','Miss.','Mrs.','Master.','ootherr'])]
temp_df

pd.crosstab(temp_df['Survived'],temp_df['title'],normalize='columns')

pd.crosstab(temp_df['Survived'],temp_df['title'],normalize='columns')*100

"""# Analysis on Cabin column"""

df2['Cabin'].isnull().sum()

df2['Cabin'].isnull().sum()/len(df2['Cabin'])

df2['Cabin'].value_counts().head(15)

df2['Cabin'].fillna('M',inplace=True)

df2['Cabin'].value_counts()

df2['Deck']=df2['Cabin'].str[0]
df2

df2['Deck'].value_counts()

pd.crosstab(df2['Deck'],df2['Pclass'])

pd.crosstab(df2['Deck'],df2['Survived'],normalize='index').plot(kind='bar',stacked=True)

"""* # Conclusion: on Deck
# in above survived is depend on Deck because above bar graph is not unifom means if don,t effect of Deck on survived then it will uniform
"""

